{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File content:\n",
    "\n",
    "Touluse CSV creation: Code for correct the street name and create the CSV files.\n",
    "\n",
    "Toulouse database and SQL queries.\n",
    "\n",
    "TOULOUSE - FRANCE IN OSM.\n",
    "Postal codes 31000, 31100, 31200,31300, 31400 and 31500 + CEDEX (those are the postal codes of Toulouse urban area).\n",
    "The Coordinates we will extract are: 43.6552N, 1.5024E, 43.5595S, 1.3935W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the list of imports we are going to use\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import codecs\n",
    "import json\n",
    "from IPython.display import Image\n",
    "import csv\n",
    "import codecs\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the corrections to be pass when CSV creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107: Cours Rosalind Franklin, 107\n",
      "6 Impasse Leonce Couture: Impasse Leonce Couture, 6\n",
      "9: Rue Reclusane, 9\n",
      "allée Fernand Jourdant: Allée Fernand Jourdant\n",
      "allées Jules-Guesde: Allées Jules-Guesde\n",
      "avenue de Lombez: Avenue de Lombez\n",
      "avenue du Colonel Roche: Avenue du Colonel Roche\n",
      "avenue Etienne Billieres: Avenue Etienne Billieres\n",
      "AVENUE JEAN RIEUX: Avenue JEAN RIEUX\n",
      "avenue jean-chaubet: Avenue jean-chaubet\n",
      "avenue Jean-Rieux: Avenue Jean-Rieux\n",
      "chemin Cassaing: Chemin Cassaing\n",
      "chemin de la Salade Ponsan: Chemin de la Salade Ponsan\n",
      "Frédéric Petit: Rue Frédéric Petit\n",
      "Lotissement Futuropolis - Impasse René Mouchotte: Impasse René Mouchotte_Lotissement Futuropolis\n",
      "place Papus: Place Papus\n",
      "place Saint-Cyprien: Place Saint-Cyprien\n",
      "ROUTE DE BLAGNAC: Route DE BLAGNAC\n",
      "route de Fronton: Route de Fronton\n",
      "route de launaguet: Route de launaguet\n",
      "rue Baour-Lormian: Rue Baour-Lormian\n",
      "rue Bénezet: Rue Bénezet\n",
      "rue de Cugnaux: Rue de Cugnaux\n",
      "rue de l'ayga: Rue de l'ayga\n",
      "rue de l'industrie: Rue de l'industrie\n",
      "rue de la Nive: Rue de la Nive\n",
      "rue des frères Lion: Rue des frères Lion\n",
      "rue du Colonel Driant: Rue du Colonel Driant\n",
      "rue henri jansou: Rue henri jansou\n",
      "rue Jacqueline Auriol: Rue Jacqueline Auriol\n",
      "rue paule raymondis: Rue paule raymondis\n",
      "rue Reclusane: Rue Reclusane\n",
      "rue Saint Roch: Rue Saint Roch\n",
      "rue Saint-Lys: Rue Saint-Lys\n",
      "rue Théodore Lenotre: Rue Théodore Lenotre\n",
      "voie du T.O.E.C.: Voie du T.O.E.C.\n"
     ]
    }
   ],
   "source": [
    "#Function to correct street name when creating CSV files\n",
    "\n",
    "dataset = 'UdcT2'\n",
    "\n",
    "street_type_re = re.compile(r'(?P<word>)(\\b\\w+\\b)', re.IGNORECASE)\n",
    "\n",
    "street_types = defaultdict(int)\n",
    "\n",
    "#List of expected street types\n",
    "\n",
    "expected = ['Rue', 'Allée', 'Avenue',  'Place', 'Impasse', 'Route', 'Chemin', 'Boulevard', \n",
    "            'Allées', 'Esplanade', 'Port', 'Promenade', 'Quai', 'Passage', 'Cheminement', \n",
    "            'Voie', 'Descente', 'Square', 'Contre-Allée','Périphérique', 'Cours', 'Parvis', \n",
    "            'Grande','Angle','Sur','face']\n",
    "\n",
    "#Dictionary to correct the capitals missing in street type\n",
    "cap_mapping = { 'route' :'Route',\n",
    "            'ROUTE' :'Route',\n",
    "            'rue' : 'Rue' ,\n",
    "            'AVENUE': 'Avenue',\n",
    "            'avenue': 'Avenue',\n",
    "            'place':  'Place' ,\n",
    "            'allées' :'Allées',\n",
    "            'allée': 'Allée',\n",
    "            'voie' :'Voie',\n",
    "           'chemin':'Chemin'\n",
    "                }\n",
    "\n",
    "# Dictionary to correct the wrong naming of street\n",
    "other_mapping = {'107':'Cours Rosalind Franklin, 107',\n",
    "         '6' :'Impasse Leonce Couture, 6' ,\n",
    "           '9': 'Rue Reclusane, 9'  ,\n",
    "          'Frédéric':'Rue Frédéric Petit',\n",
    "          'Lotissement':'Impasse René Mouchotte_Lotissement Futuropolis'\n",
    "               }\n",
    "\n",
    "# Fucntion to pring a dict sorted by key\n",
    "def print_sorted_dict(d, expression):\n",
    "    keys = d.keys()\n",
    "    keys = sorted(keys, key=lambda s: s.lower())\n",
    "    for k in keys:\n",
    "        v = d[k]\n",
    "        print (expression % (k, v))\n",
    "\n",
    "# Function to find the street in the file\n",
    "def is_street_name(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "# Function to find the street with type not in expected type\n",
    "def expected_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "# Function to find the street with not expected street type in the file\n",
    "def audit_st_tp(filename):\n",
    "    problem_street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(filename):\n",
    "        if is_street_name(elem):\n",
    "            expected_street_type(problem_street_types, elem.attrib['v'])\n",
    "    return problem_street_types\n",
    "\n",
    "#Function to define the correct streets name with wrong naming\n",
    "def other_correct(street_name, street_type):\n",
    "    if type(other_mapping[street_type]) == type('string'):\n",
    "        name = other_mapping[street_type]\n",
    "    else:\n",
    "        for key in other_mapping[street_type]:\n",
    "                name = key\n",
    "    return name\n",
    "\n",
    "# Function to correct the names of the street        \n",
    "def update_name(name):\n",
    "    street_type= name.split(' ',1)[0]\n",
    "    street_name= name.split(' ',1)[-1]        \n",
    "\n",
    "    if street_type in cap_mapping:\n",
    "        name = cap_mapping[street_type] + ' ' + street_name  \n",
    "    elif street_type in other_mapping:\n",
    "        name = other_correct(street_name, street_type)\n",
    "    return name\n",
    "\n",
    "\n",
    "#Function to create the dictionary that we will use to change the names of the streets when creating CSV\n",
    "def run_updates(filename):\n",
    "    st_types = audit_st_tp(dataset)\n",
    "    for st_type, ways in st_types.items():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name) # voy a prograr update name\n",
    "            if better_name != name:\n",
    "                corrected_names[name] = better_name\n",
    "    return corrected_names\n",
    "\n",
    "#Create the dictionary\n",
    "corrected_names = {}   \n",
    "corrected_names = run_updates(dataset)\n",
    "\n",
    "#Print the correct names\n",
    "print_sorted_dict(corrected_names, \"%s: %s\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the schema for the CSV creation\n",
    "\n",
    "SCHEMA = {\n",
    "    'node': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of CSV \n",
    "\n",
    "dataset = 'UdcT2'\n",
    "\n",
    "NODES_PATH = \"nodesT.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tagsT.csv\"\n",
    "WAYS_PATH = \"waysT.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodesT.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tagsT.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "# Funtion to correct the street\n",
    "def correct_element(v):\n",
    "    if v in corrected_names:\n",
    "        correct_value = corrected_names[v]\n",
    "    else:\n",
    "        correct_value = v\n",
    "    return correct_value\n",
    "\n",
    "#Funntion to define nodes and ways\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  \n",
    "\n",
    "    if element.tag == 'node':\n",
    "        node_attribs['id'] = element.attrib['id']\n",
    "        node_attribs['user'] = element.attrib['user']\n",
    "        node_attribs['uid'] = element.attrib['uid']\n",
    "        node_attribs['version'] = element.attrib['version']\n",
    "        node_attribs['lat'] = element.attrib['lat']\n",
    "        node_attribs['lon'] = element.attrib['lon']\n",
    "        node_attribs['timestamp'] = element.attrib['timestamp']\n",
    "        node_attribs['changeset'] = element.attrib['changeset']\n",
    "        \n",
    "        for node in element:\n",
    "            tag_dict = {}\n",
    "            tag_dict['id'] = element.attrib['id']\n",
    "            if ':' in node.attrib['k']:\n",
    "                tag_dict['type'] = node.attrib['k'].split(':', 1)[0]\n",
    "                tag_dict['key'] = node.attrib['k'].split(':', 1)[-1]\n",
    "                tag_dict['value'] = correct_element(node.attrib['v'])\n",
    "            else:\n",
    "                tag_dict['type'] = 'regular'\n",
    "                tag_dict['key'] = node.attrib['k']\n",
    "                tag_dict['value'] = correct_element(node.attrib['v'])\n",
    "            tags.append(tag_dict)\n",
    "            \n",
    "    elif element.tag == 'way':\n",
    "        way_attribs['id'] = element.attrib['id']\n",
    "        way_attribs['user'] = element.attrib['user']\n",
    "        way_attribs['uid'] = element.attrib['uid']\n",
    "        way_attribs['version'] = element.attrib['version']\n",
    "        way_attribs['timestamp'] = element.attrib['timestamp']\n",
    "        way_attribs['changeset'] = element.attrib['changeset']\n",
    "        n = 0\n",
    "        for node in element:\n",
    "            if node.tag == 'nd':\n",
    "                way_dict = {}\n",
    "                way_dict['id'] = element.attrib['id']\n",
    "                way_dict['node_id'] = node.attrib['ref']\n",
    "                way_dict['position'] = n\n",
    "                n += 1\n",
    "                way_nodes.append(way_dict)\n",
    "            if node.tag == 'tag':\n",
    "                tag_dict = {}\n",
    "                tag_dict['id'] = element.attrib['id']\n",
    "                if ':' in node.attrib['k']:\n",
    "                    tag_dict['type'] = node.attrib['k'].split(':', 1)[0]\n",
    "                    tag_dict['key'] = node.attrib['k'].split(':', 1)[-1]\n",
    "                    tag_dict['value'] = correct_element(node.attrib['v'])\n",
    "                else:\n",
    "                    tag_dict['type'] = 'regular'\n",
    "                    tag_dict['key'] = node.attrib['k']\n",
    "                    tag_dict['value'] = correct_element(node.attrib['v'])\n",
    "                tags.append(tag_dict)\n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, str) else v) for k, v in row.items()\n",
    "        })\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w',encoding=\"utf-8\") as nodes_file, \\\n",
    "    codecs.open(NODE_TAGS_PATH, 'w',encoding='utf-8') as nodes_tags_file, \\\n",
    "    codecs.open(WAYS_PATH, 'w',encoding='utf-8') as ways_file, \\\n",
    "    codecs.open(WAY_NODES_PATH, 'w',encoding='utf-8') as way_nodes_file, \\\n",
    "    codecs.open(WAY_TAGS_PATH, 'w',encoding='utf-8') as way_tags_file:\n",
    "\n",
    "        nodes_writer = csv.DictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = csv.DictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = csv.DictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = csv.DictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = csv.DictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow((el['way']))\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "                    \n",
    "process_map(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now the CSV file created, we can create our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating database on disk\n",
    "\n",
    "sqlite_file = 'UdcTls.db'\n",
    "\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('''DROP TABLE IF EXISTS nodes''')\n",
    "c.execute('''DROP TABLE IF EXISTS nodes_tags''')\n",
    "c.execute('''DROP TABLE IF EXISTS ways''')\n",
    "c.execute('''DROP TABLE IF EXISTS ways_tags''')\n",
    "c.execute('''DROP TABLE IF EXISTS ways_nodes''')\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "\n",
    "QUERY_NODES = \"\"\"\n",
    "CREATE TABLE nodes (\n",
    "    id INTEGER NOT NULL,\n",
    "    lat REAL,\n",
    "    lon REAL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version INTEGER,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "QUERY_NODES_TAGS = \"\"\"\n",
    "CREATE TABLE nodes_tags (\n",
    "    id INTEGER,\n",
    "    key TEXT,\n",
    "    value TEXT,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES nodes(id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "QUERY_WAYS = \"\"\"\n",
    "CREATE TABLE ways (\n",
    "    id INTEGER NOT NULL,\n",
    "    user TEXT,\n",
    "    uid INTEGER,\n",
    "    version INTEGER,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "QUERY_WAYS_TAGS = \"\"\"\n",
    "CREATE TABLE ways_tags (\n",
    "    id INTEGER NOT NULL,\n",
    "    key TEXT NOT NULL,\n",
    "    value TEXT NOT NULL,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "QUERY_WAYS_NODES = \"\"\"\n",
    "CREATE TABLE ways_nodes (\n",
    "    id INTEGER NOT NULL,\n",
    "    node_id INTEGER NOT NULL,\n",
    "    position INTEGER NOT NULL,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id),\n",
    "    FOREIGN KEY (node_id) REFERENCES nodes(id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "c.execute(QUERY_NODES)\n",
    "c.execute(QUERY_NODES_TAGS)\n",
    "c.execute(QUERY_WAYS)\n",
    "c.execute(QUERY_WAYS_TAGS)\n",
    "c.execute(QUERY_WAYS_NODES)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating structure of database\n",
    "\n",
    "with open('nodes.csv','rt', encoding='utf8') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db1 = [(i['id'], i['lat'], i['lon'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "    \n",
    "with open('nodes_tags.csv','rt',encoding='utf8') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db2 = [(i['id'], i['key'], i['value'], i['type']) for i in dr]\n",
    "    \n",
    "with open('ways.csv','rt', encoding='utf8') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db3 = [(i['id'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "    \n",
    "with open('ways_tags.csv','rt', encoding='utf8') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db4 = [(i['id'], i['key'], i['value'], i['type']) for i in dr]\n",
    "    \n",
    "with open('ways_nodes.csv','rt', encoding='utf8') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db5 = [(i['id'], i['node_id'], i['position']) for i in dr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling the database\n",
    "\n",
    "c.executemany(\"INSERT INTO nodes(id, lat, lon, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?, ?, ?);\", to_db1)\n",
    "c.executemany(\"INSERT INTO nodes_tags(id, key, value, type) VALUES (?, ?, ?, ?);\", to_db2)\n",
    "c.executemany(\"INSERT INTO ways(id, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?);\", to_db3)\n",
    "c.executemany(\"INSERT INTO ways_tags(id, key, value, type) VALUES (?, ?, ?, ?);\", to_db4)\n",
    "c.executemany(\"INSERT INTO ways_nodes(id, node_id, position) VALUES (?, ?, ?);\", to_db5)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes in the data base: [(956186,)]\n",
      "Ways in data base: [(160279,)]\n"
     ]
    }
   ],
   "source": [
    "# Query to count the nodes and ways in database\n",
    "c.execute('SELECT COUNT(*) FROM nodes')\n",
    "all_rows = c.fetchall()\n",
    "print('Nodes in the data base:', all_rows)\n",
    "\n",
    "c.execute('SELECT COUNT(*) FROM ways')\n",
    "all_rows = c.fetchall()\n",
    "print('Ways in data base:',all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 contributors and their contributions: [('Pinpin', 296412), ('emarsden', 189554), ('don-vip', 69909), ('Sebastien Dinot', 60055), ('Hervé TUC', 47052), ('Tyndare', 27593), ('isnogoud', 26753), ('square', 24542), ('Florence Birée', 21728), ('capdarmen', 21454), ('FredB', 20517), ('orhygine', 15530), ('Luuuddooo', 12966), ('Carboon33', 10143), ('Floeditor', 7126)]\n"
     ]
    }
   ],
   "source": [
    "# Query to show the nicknames *user* and contributions of the top 15 contributors\n",
    "QUERY = '''\n",
    "SELECT DISTINCT nodes.user, COUNT(*)\n",
    "FROM nodes\n",
    "GROUP BY nodes.user\n",
    "ORDER BY COUNT(*) DESC\n",
    "LIMIT 15;\n",
    "'''\n",
    "c.execute(QUERY)\n",
    "all_rows = c.fetchall()\n",
    "print('Top 15 contributors and their contributions:',all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 contributors and their contributions: [('Pinpin', 30.99940806495807), ('emarsden', 19.823967303432596), ('don-vip', 7.311234425101392), ('Sebastien Dinot', 6.280681792036278), ('Hervé TUC', 4.920799928047472), ('Tyndare', 2.885735620475514), ('isnogoud', 2.7978866036524273), ('square', 2.566655441514517), ('Florence Birée', 2.2723612351571765), ('capdarmen', 2.243705722526789)]\n"
     ]
    }
   ],
   "source": [
    "# Query to show nicknames *user* and contributions of the top 10 contributors in %\n",
    "QUERY = '''\n",
    "SELECT DISTINCT nodes.user, COUNT(*) * 100.0 / (SELECT COUNT(*) FROM nodes)\n",
    "FROM nodes\n",
    "GROUP BY nodes.uid\n",
    "ORDER BY (COUNT(*) * 100.0 / (SELECT COUNT(*) FROM nodes)) DESC\n",
    "LIMIT 10;\n",
    "'''\n",
    "\n",
    "c.execute(QUERY)\n",
    "all_rows = c.fetchall()\n",
    "print('Top 10 contributors and the % of their contributions:', all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 source of informations: [('ToulouseMetropole', 35380), ('GrandToulouse', 16958), ('cadastre-dgi-fr source : Direction Générale des Impôts - Cadastre. Mise à jour : 2009', 8113), ('cadastre-dgi-fr source : Direction Générale des Impôts - Cadastre. Mise à jour : 2011', 3445), ('survey', 1924), ('Bing', 1442), ('cadastre-dgi-fr source : Direction Générale des Impôts - Cadastre. Mise à jour : 2010', 974), ('http://data.grandtoulouse.fr', 718), ('https://www.tisseo.fr', 624), ('ToulouseMetropole - Orthophotoplan 2015', 611), ('cadastre-dgi-fr source : Direction Générale des Impôts - Cadastre ; mise à jour : 2008', 571), ('cadastre-dgi-fr source : Direction Générale des Impôts - Cadastre. Mise à jour : 2014', 558), ('Enedis - 06/2018', 449), ('INSEE - 06/2019', 288), ('cadastre-dgi-fr source : Direction Générale des Impôts - Cadastre ; mise à jour : 2011', 195)]\n"
     ]
    }
   ],
   "source": [
    "# Query to see the source of information\n",
    "QUERY = '''\n",
    "SELECT value, COUNT(*) as Count\n",
    "FROM nodes_tags\n",
    "WHERE key='source'\n",
    "GROUP BY value\n",
    "ORDER BY Count DESC\n",
    "LIMIT 15;\n",
    "'''\n",
    "\n",
    "c.execute(QUERY)\n",
    "all_rows = c.fetchall()\n",
    "print('Top 15 source of informations:',all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 source of informations in %: [('ToulouseMetropole', 11.459888769762477), ('GrandToulouse', 5.492843237920636), ('cadastre-dgi-fr source : Direction Générale des Impôts - Cadastre. Mise à jour : 2009', 2.6278710454800165), ('cadastre-dgi-fr source : Direction Générale des Impôts - Cadastre. Mise à jour : 2011', 1.1158653706001056), ('survey', 0.6232002824483609), ('Bing', 0.4670763031655594), ('cadastre-dgi-fr source : Direction Générale des Impôts - Cadastre. Mise à jour : 2010', 0.3154870452727149), ('http://data.grandtoulouse.fr', 0.2325664255706461), ('https://www.tisseo.fr', 0.20211901052379272), ('ToulouseMetropole - Orthophotoplan 2015', 0.19790819780454702)]\n"
     ]
    }
   ],
   "source": [
    "# Query to show % of information by source \n",
    "QUERY = '''\n",
    "SELECT value, COUNT(*) * 100.0 / (SELECT COUNT(*) FROM nodes_tags)\n",
    "FROM nodes_tags\n",
    "WHERE key='source'\n",
    "GROUP BY value\n",
    "ORDER BY (COUNT(*) * 100.0 / (SELECT COUNT(*) FROM nodes)) DESC\n",
    "LIMIT 10;\n",
    "'''\n",
    "\n",
    "c.execute(QUERY)\n",
    "all_rows = c.fetchall()\n",
    "print('Top 10 source of informations in %:',all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Avenue des États-Unis', 70), ('Boulevard André Netwiller', 65), ('Route de Narbonne', 65), (\"Avenue d'Atlanta\", 64), (\"Route d'Albi\", 55), ('Ligne de Bordeaux à Sète', 53), ('Ligne de Toulouse à Bayonne', 53), ('Rue Saint-Jean', 49), ('Autoroute des Deux Mers', 48), ('Allées Charles de Fitte', 46)]\n"
     ]
    }
   ],
   "source": [
    "# Query to count the tags with more nodes, show top 10\n",
    "QUERY = '''\n",
    "SELECT ways_tags.value, COUNT(*)\n",
    "FROM ways_tags\n",
    "WHERE ways_tags.key = 'name'\n",
    "AND ways_tags.type = 'regular'\n",
    "GROUP BY ways_tags.value\n",
    "ORDER BY COUNT(*) DESC\n",
    "LIMIT 10;\n",
    "'''\n",
    "\n",
    "c.execute(QUERY)\n",
    "all_rows = c.fetchall()\n",
    "print(all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bench', 985), ('recycling', 895), ('restaurant', 726), ('bicycle_parking', 667), ('waste_basket', 443), ('fast_food', 356), ('bicycle_rental', 286), ('post_box', 279), ('parking', 275), ('vending_machine', 187), ('drinking_water', 181), ('bar', 178), ('cafe', 172), ('pharmacy', 163), ('bank', 157)]\n"
     ]
    }
   ],
   "source": [
    "# Query to count the top 15 amenities\n",
    "QUERY = '''\n",
    "SELECT value, COUNT(*) as Count\n",
    "FROM nodes_tags\n",
    "WHERE key='amenity'\n",
    "GROUP BY value\n",
    "ORDER BY Count DESC\n",
    "LIMIT 15;\n",
    "'''\n",
    "\n",
    "c.execute(QUERY)\n",
    "all_rows = c.fetchall()\n",
    "print(all_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If after reading this project you decide to come to visit Touluse you will have enouth place to eat with 726 restaurant, 356 fast-food, 178 bar and 172 cafe\n",
    "And if you need money you can go to one of the 157 banks\n",
    "You can rent a bicycle in one of the 286 rental point\n",
    "Or send a postcard to your friends from one of the 279 post box\n",
    "If after all that you are tyred you can set in one fo the 985 bench that are spread in the city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('french', 91), ('pizza', 42), ('regional', 29), ('japanese', 26), ('asian', 25), ('indian', 21), ('italian', 20), ('chinese', 17), ('vietnamese', 13), ('burger', 11), ('lebanese', 9), ('pancake', 7), ('seafood', 6), ('thai', 6), ('crepe', 5), ('spanish', 5), ('sushi', 5), ('african', 4), ('moroccan', 4), ('brasserie', 3), ('couscous', 3), ('international', 3), ('kebab', 3), ('tapas', 3), ('american', 2), ('arab', 2), ('argentinian', 2), ('caribbean', 2), ('latin_american', 2), ('local', 2), ('mexican', 2), ('sandwich', 2), ('steak_house', 2), ('Gastronomique', 1), ('american;burger;brunch', 1), ('asian;thai', 1), ('asian;vietnamese', 1), ('asian;wok;japanese;chinese;regional', 1), ('beer;bistro', 1), ('bio', 1), ('burger;friture;belgian;mussel', 1), ('burger;pizza;french', 1), ('burger;tapas', 1), ('burger;tapas;french', 1), ('cake', 1), ('cake;teahouse', 1), ('chicken', 1), ('chilean', 1), ('corsican', 1), ('coréen;Asiatique;Végétarien;Végétalien;sandwich;japanese;beef_bowl;Poke_Bowl;du_monde', 1), ('crepe;salad;waffle', 1), ('crêpes;galettes;french;breton', 1), ('ethiopian', 1), ('french,_regional', 1), ('french;meat', 1), ('french;portuguese', 1), ('french;pâtisserie', 1), ('french;regional', 1), ('french;végétarien', 1), ('greek;souvlaki', 1), ('grill;french;coffee_shop;local;friture;steak_house;beef_bowl;diner', 1), ('hawaii', 1), ('international;french', 1), ('italian;pasta;pizza', 1), ('italian;pizza', 1), ('italian_pizza', 1), ('japanese;thai', 1), ('japanese;traditional', 1), ('korean', 1), ('mediterranean', 1), ('moroccan;mediterranean', 1), ('nepalese;tibetan', 1), ('norwegian', 1), ('paleo', 1), ('pasta', 1), ('pasta;pizza;fish;tapas;salad;barbecue', 1), ('peruvian', 1), ('pintxos', 1), ('pizza;italian', 1), ('pizza;salad', 1), ('poke', 1), ('poke;salad;sandwich;smoothie', 1), ('portuguese; african; cap vert', 1), ('ramen;japanese;vietnamese', 1), ('regional;french', 1), ('regional;french;sandwich', 1), ('regional;tapas', 1), ('russian', 1), ('salad', 1), ('savory_pancakes;regional', 1), ('seafood;mussel', 1), ('snack;tea', 1), ('tacos', 1), ('tapas;dessert', 1), ('tapas;fusion', 1), ('tea', 1), ('thai;sushi', 1), ('tunisian', 1), ('vietnamese;asian', 1), ('vietnamese;china', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Query to count the cuisine of the restaurant\n",
    "QUERY = '''\n",
    "SELECT nodes_tags.value, COUNT(*) as count\n",
    "FROM nodes_tags \n",
    "JOIN\n",
    "    (SELECT DISTINCT(id)\n",
    "    FROM nodes_tags\n",
    "    WHERE value='restaurant') as Sub\n",
    "ON nodes_tags.id=Sub.id\n",
    "WHERE nodes_tags.key='cuisine'\n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY Count DESC;\n",
    "'''\n",
    "\n",
    "c.execute(QUERY)\n",
    "all_rows = c.fetchall()\n",
    "print(all_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we check the type of cuisien we have a winner: the French cuisine, what such surprise!!!\n",
    "But if you finaly come, I recomend you to taste the local cuisine in one of the 29 regional restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do yo prefer fast-food, we have some too: [('Subway', 7), (\"McDonald's\", 6), (\"Domino's\", 4), (\"Domino's Pizza\", 3), ('Burger King', 2), ('KFC', 2), (\"O'Tacos\", 2), ('Quick', 2), ('Bagelstein', 1), ('Big Fernand', 1), ('Pizza Pizza', 1), ('Sushi Shop', 1), ('Tutti Pizza', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Query to see the brands of fast-food \n",
    "QUERY = '''\n",
    "SELECT nodes_tags.value, COUNT(*) as count\n",
    "FROM nodes_tags \n",
    "JOIN\n",
    "    (SELECT DISTINCT(id)\n",
    "    FROM nodes_tags\n",
    "    WHERE value='fast_food') as Sub\n",
    "ON nodes_tags.id=Sub.id\n",
    "WHERE nodes_tags.key='brand'\n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY Count DESC;\n",
    "'''\n",
    "\n",
    "c.execute(QUERY)\n",
    "all_rows = c.fetchall()\n",
    "print('Do yo prefer fast-food, we have some too:',all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to go shopping? [('clothes', 466), ('hairdresser', 279), ('bakery', 181), ('convenience', 159), ('beauty', 111), ('jewelry', 110), ('butcher', 100), ('shoes', 94), ('vacant', 91), ('optician', 82)]\n"
     ]
    }
   ],
   "source": [
    "# Query to count the top 10 shop types\n",
    "QUERY = '''\n",
    "SELECT value, COUNT(*) as Count\n",
    "FROM nodes_tags\n",
    "WHERE key='shop'\n",
    "GROUP BY value\n",
    "ORDER BY Count DESC\n",
    "LIMIT 10;\n",
    "'''\n",
    "\n",
    "c.execute(QUERY)\n",
    "all_rows = c.fetchall()\n",
    "print('Do you want to go shopping?',all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You want to know at what time the postcard for your friend will be collected: [('Mo-Fr 12:00, Sa 11:00', 38), ('Mo-Fr 12:00; Sa 11:00', 4), ('Mo-Fr 16:00, Sa 11:00', 4), ('Mo-Fr 12:00, Sa 09:00', 3), ('Mo-Fr 08:30-18:30;Sa 09:00-12:30', 1), ('Mo-Fr 12:00, Sa unknown', 1), ('Mo-Fr 12:00,Sa 11:00', 1), ('Mo-Fr 15:00, Sa 11:00', 1), ('Mo-Fr 16:30; Sa 11:15', 1), ('Mo-Fr 17:00, Sa 12:00', 1), ('Mo-Fr 17:00; Sa 12:00', 1), ('Mo-Fr 18:00, Sa 11:00', 1), ('Mo-Sa 9:30', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Query to find the normal time the mail is colected in the post office\n",
    "QUERY = '''\n",
    "SELECT value, COUNT(*) as Count\n",
    "FROM nodes_tags\n",
    "WHERE key='collection_times'\n",
    "GROUP BY value\n",
    "ORDER BY Count DESC\n",
    "LIMIT 15;\n",
    "'''\n",
    "\n",
    "c.execute(QUERY)\n",
    "all_rows = c.fetchall()\n",
    "print('You want to know at what time the postcard for your friend will be collected:',all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now some sport: [('fitness', 28), ('boules', 10), ('multi', 8), ('table_tennis', 7), ('climbing', 4), ('basketball', 3), ('boxing', 3), ('soccer', 3), ('swimming', 3), ('yoga', 3), ('aikido', 2), ('crossfit', 2), ('gymnastics', 2), ('handball', 2), ('rowing', 2)]\n"
     ]
    }
   ],
   "source": [
    "# Query to find the type of sport places\n",
    "QUERY = '''\n",
    "SELECT value, COUNT(*) as Count\n",
    "FROM nodes_tags\n",
    "WHERE key='sport'\n",
    "GROUP BY value\n",
    "ORDER BY Count DESC\n",
    "LIMIT 15;\n",
    "'''\n",
    "\n",
    "c.execute(QUERY)\n",
    "all_rows = c.fetchall()\n",
    "print('Now some sport:',all_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 4 places for climbing, as we need to be trainned for our trips to Pyrinees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But you come for tourism, dont you?: [('information', 142), ('artwork', 83), ('hotel', 65), ('gallery', 28), ('attraction', 24), ('picnic_site', 20), ('viewpoint', 12), ('museum', 10), ('apartment', 3), ('guest_house', 3), ('caravan_site', 1), ('gallerie', 1), ('hostel', 1), ('motel', 1), ('theme_park', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Query to find the tourism things \n",
    "QUERY = '''\n",
    "SELECT value, COUNT(*) as Count\n",
    "FROM nodes_tags\n",
    "WHERE key='tourism'\n",
    "GROUP BY value\n",
    "ORDER BY Count DESC\n",
    "LIMIT 15;\n",
    "'''\n",
    "\n",
    "c.execute(QUERY)\n",
    "all_rows = c.fetchall()\n",
    "print('But you come for tourism, dont you?:',all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you need to find a place for the night, you can chose amoung those: [('Ibis', 3), ('Novotel', 2), ('Adagio Access', 1), ('Adagio Access Toulouse St Cyprien', 1), ('Apart Hotel Citadines', 1), ('Aparthôtel Lagrange City Toulouse Saint-Michel', 1), (\"Appart'City Hippodrome\", 1), ('At Home Appart Hotel', 1), ('Auberge de Jeunesse', 1), ('B&b Hôtel', 1), ('B&b Hôtel Toulouse Centre', 1), ('Best Western Athénée', 1), ('Best Western Les Capitouls', 1), ('Castellane', 1), ('Crowne Plaza', 1), ('Excelsior', 1), ('Garden Hôtel', 1), (\"Grand Hôtel D'Orléans\", 1), (\"Grand Hôtel de l'Opéra\", 1), ('Hôtel Arnaud Bernard', 1), ('Hôtel Chartreuse', 1), ('Hôtel Croix Baragnon', 1), ('Hôtel Hermès', 1), ('Hôtel Icare', 1), ('Hôtel Junior', 1), ('Hôtel Kyriad', 1), ('Hôtel Le Prado', 1), ('Hôtel Mercure Toulouse Centre Compans', 1), ('Hôtel Mermoz', 1), ('Hôtel Occitania', 1), ('Hôtel Orsay', 1), ('Hôtel Raymond 4', 1), ('Hôtel ResidHome', 1), ('Hôtel Riquet', 1), ('Hôtel Saint-Sernin', 1), ('Hôtel Victor Hugo', 1), ('Hôtel Wilson Square', 1), ('Hôtel aux Ambassadeurs', 1), ('Hôtel de Brienne', 1), ('Hôtel de France', 1), ('Hôtel des Arts', 1), ('Hôtel des Beaux Arts', 1), ('Hôtel ibis Styles', 1), ('Hôtel le Pastel', 1), ('Ibis Budget', 1), ('Ibis Styles', 1), ('Ibis Toulouse Pont Jumeaux', 1), ('Ibis Toulouse Purpan', 1), ('La Caravelle', 1), ('Le 30 étoiles', 1), ('Le Boutique Hôtel Garonne', 1), ('Le Bristol', 1), ('Le Cousture', 1), ('Le Deauville', 1), ('Le Père Léon', 1), ('Mercure Toulouse Saint-Georges', 1), ('Mercure Toulouse Wilson', 1), (\"Pays d'Oc\", 1), ('Privilege Appart-Hotel Clément Ader', 1), ('Pullman Toulouse Centre Ramblas', 1), ('Saint-Severin', 1), ('Villa du Taur', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Query to see the brands of fast-food \n",
    "QUERY = '''\n",
    "SELECT nodes_tags.value, COUNT(*) as count\n",
    "FROM nodes_tags \n",
    "JOIN\n",
    "    (SELECT DISTINCT(id)\n",
    "    FROM nodes_tags\n",
    "    WHERE value='hotel') as Sub\n",
    "ON nodes_tags.id=Sub.id\n",
    "WHERE nodes_tags.key='name'\n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY Count DESC;\n",
    "'''\n",
    "\n",
    "c.execute(QUERY)\n",
    "all_rows = c.fetchall()\n",
    "print('Now you need to find a place for the night, you can chose amoung those:',all_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that is all about my city, hope you enjoy the trip."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
